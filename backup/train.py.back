from __future__ import print_function
import argparse
import torch
import torch.nn as nn
import torch.optim as optim

import datetime
import pandas as pd
from torch.utils.data import DataLoader

#Import my model and Dataset
from dataload import StasDataset 
from model import DNN
from main import test, train, train_main
import sys
import os

parser = argparse.ArgumentParser(description='NI: Stas Action Classification') 
parser.add_argument('--data', type=str, default="dummy",
                    help='dataset for experiments varied by charactersitic of dummies (dummy, dummy0.2, dummy0.1, dummy2)')
parser.add_argument('--batch_size', type=int, default=16, metavar='N',
                    help='input batch size for training (default: 64)')
parser.add_argument('--epochs', type=int, default=3000, metavar='N',
                    help='number of epochs to train (default: 10)')
parser.add_argument('--optim', type=str, default="RMSprop")
parser.add_argument('--lr', type=float, metavar='LR', default=0.01,
                    help='learning rate (no default)')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                    help='how many batches to wait before logging training status')
parser.add_argument('--patience', type=int, default=15, metavar='P',
                    help='Early Stopping Patience')
parser.add_argument('--val_freq', type=int, default=1, metavar='VF',
                    help='Validation Test Frequency')
parser.add_argument('--saveto', type=str, default='./saveto')
parser.add_argument('--VNF', type=str, default='firewall')
parser.add_argument('--horizon', type=int, default=10)
parser.add_argument('--hidden1', type=int, default=40)
parser.add_argument('--hidden2', type=int, default=30)
parser.add_argument('--hidden3', type=int, default=10)
parser.add_argument('--expName', type=str, default="sample")

args = parser.parse_args()
args.device = torch.device("cuda")
args.test_batch_size = args.batch_size

# make dataloader
csv_path = os.path.join("../data", args.data, "train.csv")
train_data = StasDataset(csv_path, args.horizon)
trainLoader = DataLoader(train_data, args.batch_size, shuffle=True)

csv_path = os.path.join("../data", args.data, "valid.csv")
valid_data = StasDataset(csv_path, args.horizon)
validLoader = DataLoader(valid_data, args.batch_size, shuffle=True)

csv_path = os.path.join("../data", args.data, "test.csv")
test_data = StasDataset(csv_path, args.horizon)
testLoader = DataLoader(test_data, args.batch_size, shuffle=True)

# do experiment for n_exp times
n_exp = 5
accs =[]
f1s = []

for n in range(n_exp):
	model = DNN(args)
	print("Setting Model Complete")
	model.to(args.device)

	optimizer = "optim." + args.optim
	optimizer = eval(optimizer)(model.parameters(), lr=args.lr)
	#optimizer = optim.RMSprop(model.parameters())
	#optimizer = optim.Adam(model.parameters())
	#oprimizer = optim.SGD(model.parameters())
	
	print("Setting optimizer Complete")
	
	train_main(model, args, trainLoader, validLoader, optimizer)
	acc, f1 = test(model, args, testLoader)
	
	accs.append(acc)
	f1s.append(f1)

print("=" * 90)
print("results on testset at each trials:")

for i in range(n_exp):
	print("exp {:d} | acc {:.3f} | f1 {:.3f}".format(i+1, accs[i], f1s[i]))	

total_acc = sum(accs) / n_exp
total_f1 = sum(f1s) / n_exp

print("-" * 90)
print("total scores")
print("acc {:.3f} | f1 {:.3f}".format(sum(accs)/n_exp, sum(f1s)/n_exp))
print("=" * 90)

# make logs of results
hiddens = str(args.hidden1) + "_" + str(args.hidden2) + "_" + str(args.hidden3)

with open(os.path.join(args.saveto, args.expName + ".result"), 'a') as fp:
	#fp.write(str(optim) + ',' + str(args.lr) + ',' + hiddens + ',' + str(args.patience) + ',' + str(args.batch_size) + ','+ str(total_acc) ',' + str(total_f1))
	fp.write("{:s},{:f},{:s},{:d},{:d},{:f},{:f}\n".format(args.optim, args.lr, hiddens, args.patience, args.batch_size, total_acc, total_f1))
